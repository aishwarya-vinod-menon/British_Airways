{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping Page 1\n",
      "Scrapping Page 2\n",
      "Scrapping Page 3\n",
      "Scrapping Page 4\n",
      "Scrapping Page 5\n",
      "Scrapping Page 6\n",
      "Scrapping Page 7\n",
      "Scrapping Page 8\n",
      "Scrapping Page 9\n",
      "Scrapping Page 10\n"
     ]
    }
   ],
   "source": [
    "base=\"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "# Creating Lists for all the info that we need\n",
    "reviews=[]\n",
    "date=[]\n",
    "country=[]\n",
    "stars=[]\n",
    "\n",
    "for i in range(1,11):\n",
    "    print(f\"Scrapping Page {i}\")\n",
    "    url=f\"{base}/page/{i}/?sortby=post_date%3ADesc&pagesize={100}\"\n",
    "    #sending HTTP request to the page\n",
    "    response=requests.get(url)\n",
    "    #parse contents\n",
    "    content=response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    table = parsed_content.find('h3', attrs = {'class':'text_sub_header userStatusWrapper'})  \n",
    "\n",
    "    for p in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(p.get_text())\n",
    "    for item in parsed_content.find_all(\"time\"):\n",
    "        date.append(item.text)\n",
    "    for item in parsed_content.find_all(\"h3\"):\n",
    "        country.append(item.span.next_sibling.text.strip(\" ()\"))\n",
    "    for item in parsed_content.find_all(\"div\", class_ = \"rating-10\"):\n",
    "        try:\n",
    "            stars.append(item.span.text)\n",
    "        except:\n",
    "            print(f\"Error on page {i}\")\n",
    "            stars.append(\"None\")\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking all the lengths\n",
    "len(reviews)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since the number of stars are more we reduce it\n",
    "stars=stars[0:1000]\n",
    "len(stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified | The customer services (call ...</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5</td>\n",
       "      <td>14th October 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |   I am a frequent flyer with...</td>\n",
       "      <td>3</td>\n",
       "      <td>14th October 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Flew with BA to Punta Cana. To...</td>\n",
       "      <td>5</td>\n",
       "      <td>12th October 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified |   They downgraded me from bu...</td>\n",
       "      <td>4</td>\n",
       "      <td>12th October 2023</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |   The already delayed aircra...</td>\n",
       "      <td>1</td>\n",
       "      <td>11th October 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0  ✅ Trip Verified | The customer services (call ...   \n",
       "1  ✅ Trip Verified |   I am a frequent flyer with...   \n",
       "2  Not Verified |  Flew with BA to Punta Cana. To...   \n",
       "3  ✅ Trip Verified |   They downgraded me from bu...   \n",
       "4  ✅ Trip Verified |   The already delayed aircra...   \n",
       "\n",
       "                           stars               date         country  \n",
       "0  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5  14th October 2023  United Kingdom  \n",
       "1                              3  14th October 2023  United Kingdom  \n",
       "2                              5  12th October 2023  United Kingdom  \n",
       "3                              4  12th October 2023       Australia  \n",
       "4                              1  11th October 2023  United Kingdom  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"reviews\":reviews,\"stars\":stars,\"date\":date,\"country\":country})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/python(me)/british-airways/BA_reviews2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are done with the data collection. We must next focus on cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified | The customer services (call ...</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5</td>\n",
       "      <td>14th October 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |   I am a frequent flyer with...</td>\n",
       "      <td>3</td>\n",
       "      <td>14th October 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Flew with BA to Punta Cana. To...</td>\n",
       "      <td>5</td>\n",
       "      <td>12th October 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified |   They downgraded me from bu...</td>\n",
       "      <td>4</td>\n",
       "      <td>12th October 2023</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |   The already delayed aircra...</td>\n",
       "      <td>1</td>\n",
       "      <td>11th October 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0  ✅ Trip Verified | The customer services (call ...   \n",
       "1  ✅ Trip Verified |   I am a frequent flyer with...   \n",
       "2  Not Verified |  Flew with BA to Punta Cana. To...   \n",
       "3  ✅ Trip Verified |   They downgraded me from bu...   \n",
       "4  ✅ Trip Verified |   The already delayed aircra...   \n",
       "\n",
       "                           stars               date         country  \n",
       "0  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5  14th October 2023  United Kingdom  \n",
       "1                              3  14th October 2023  United Kingdom  \n",
       "2                              5  12th October 2023  United Kingdom  \n",
       "3                              4  12th October 2023       Australia  \n",
       "4                              1  11th October 2023  United Kingdom  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
